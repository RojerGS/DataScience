---
title: "moneyball"
author: "Rodrigo Girão Serrão"
date: "14 de Novembro de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r imports}
library(Lahman)
library(tidyverse)
library(ggplot2)
```

Explore the data for the baseball teams. What is the relationship between home runs and total runs per game, between stolen bases and total runs and between bases on balls and total runs?

```{r explore_data}
names(Teams)
myteams <- Teams %>% filter(yearID %in% 1962:2001) %>% mutate(R_per_game = R/G)

myteams %>%
  mutate(HR_per_game = HR/G) %>%
  ggplot(aes(HR_per_game, R_per_game)) + geom_point(alpha=0.4)

myteams %>%
  mutate(SB_per_game = SB/G) %>%
  ggplot(aes(SB_per_game, R_per_game)) + geom_point(alpha=0.4)
myteams %>%
  mutate(BB_per_game = BB/G) %>%
  ggplot(aes(BB_per_game, R_per_game)) + geom_point(alpha=0.4)
```

Compute the correlation between home runs and total number of runs with the formula.

```{r correlation}
mur = mean(myteams$R_per_game)
sdr = sd(myteams$R_per_game)
homeruns <- myteams %>% mutate(HR_per_game=HR/G)
muhr = mean(homeruns$HR_per_game)
sdhr = sd(homeruns$HR_per_game)
1/length(homeruns$HR_per_game)*sum(((homeruns$HR_per_game-muhr)/sdhr)*((homeruns$R_per_game-mur)/sdr))
```

We will try to understand if BB can be used to predict the runs. We stratify HR, however, as HR and BB are confounded. The correlation between BB and R, if we ignore HR, is 0.735. When we stratify, the slopes become:

```{r strats}
# stratify the data
dat <- myteams %>% mutate(HR_strata = round(HR/G,1)) %>%
        mutate(BB_per_game=BB/G) %>% filter(HR_strata >= 0.4 & HR_strata <= 1.2)

dat %>% ggplot(aes(BB_per_game, R_per_game)) +
          geom_point(alpha=0.5) + 
          geom_smooth(method="lm") +
          facet_wrap(~HR_strata)
```

Now I will build some linear models to try and predict the number of runs per game with the number of home runs per game and the number of bases on balls per game.

```{r lm_runs_per_game}
dat <- myteams %>% mutate(HR_per_game=HR/G, BB_per_game=BB/G)
fit1 <- dat %>% lm(R_per_game ~ BB_per_game, data=.)
fit2 <- dat %>% lm(R_per_game ~ HR_per_game, data=.)
fit3 <- dat %>% lm(R_per_game ~ HR_per_game + BB_per_game, data=.)

summary(fit1)
summary(fit2)
summary(fit3)
```

Now we notice that the LSE are random variables. For that, make use of the Galton historical data and assume it represents the whole population. Then, sample the population and compute its estimates. Store the results to show the estimates follow a normal distribution.

```{r lse}
library(HistData)
library(gridExtra)
data("GaltonFamilies")
heights <- GaltonFamilies %>% filter(childNum == 1) %>%
            select(father, childHeight)

B <- 1000
N <- 50
lse <- replicate(B, {
  heights %>% sample_n(N) %>% lm(childHeight ~ father, data=.) %>% .$coef
})
lse <- data.frame(beta0 = lse[1,], beta1 = lse[2,])

p1 <- lse %>% ggplot(aes(beta0)) + geom_histogram(binwidth=5, color="black")
p2 <- lse %>% ggplot(aes(beta1)) + geom_histogram(binwidth=0.1, color="black")
grid.arrange(p1, p2, ncol=2)

qqnorm(lse$beta0)
qqnorm(lse$beta1)
```

Notice that the correlation between $\beta_0$ and $\beta_1$ changes when we center the father's heights.

```{r correlation}
lse %>% summarise(cor(beta0, beta1))

B <- 1000
N <- 50
lse <- replicate(B, {
  heights %>% sample_n(N) %>%
      mutate(father=father-mean(father)) %>% lm(childHeight ~ father, data=.) %>% .$coef
})
cor(lse[1,], lse[2,])
```

We can plot the predictions with confidence intervals. `ggplot2` can do that with little effort or we can do it by hand:

```{r confidence_intervals}
heights %>% ggplot(aes(childHeight, father)) + geom_point() + geom_smooth(method="lm")

model <- lm(childHeight ~ father, data = heights)
predictions <- predict(model, interval = c("confidence"), level = 0.95)
data <- as.tibble(predictions) %>% bind_cols(father = heights$father)

ggplot(data, aes(x = father, y = fit)) +
  geom_line(color = "blue", size = 1) + 
  geom_ribbon(aes(ymin=lwr, ymax=upr), alpha=0.2) + 
  geom_point(data = heights, aes(x = father, y = childHeight))
```

The `lm` function does not know how to deal with grouped tibbles so we need to use the `do` function when we pipe grouped results into the `lm`:

```{r do_function}
# refresh the data frame
dat <- Teams %>% filter(yearID %in% 1961:2001) %>%
        mutate(HR = round(HR/G, 1),
                BB = BB/G,
                R = R/G) %>%
        select(HR, BB, R) %>%
        filter(HR >= 0.4 & HR <= 1.2)

extract_useful_info <- function(d) {
  fit <- lm(R~BB, data=d)
  data.frame(slope=fit$coefficients[2],
              se = summary(fit)$coefficients[2,2],
              row.names = NULL)
}

save <- dat %>% group_by(HR) %>% do(extract_useful_info(.))
```

Use the `broom` package to interface between `lm` and the `tidyverse`.

```{r broom}
library(broom)

temp <- dat %>% group_by(HR) %>%
        do(tidy(lm(R~BB, data=.), conf.int=TRUE)) %>%
        filter(term == "BB") %>%
        select(HR, estimate, conf.low, conf.high)
temp
temp %>% ggplot(aes(HR, estimate, ymin=conf.low, ymax=conf.high)) +
          geom_errorbar() + geom_point()
```