{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# make this point to the file with the clean tweets\n",
    "DATAFILE = \"data_clean_stemmed_withoutRT.csv\"\n",
    "# make this point to the file with the text tweets\n",
    "TWEETSFILE = \"data_original_notStemmed_withoutRT.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the tweets\n",
    "text_tweets = pandas.read_csv(TWEETSFILE, index_col=0)\n",
    "# read the csv\n",
    "data = pandas.read_csv(DATAFILE, index_col=0)\n",
    "# get all the tweets\n",
    "# as of now, they are still strings, the string representation of the list\n",
    "tweets = []\n",
    "for tweet in data[\"text\"]:\n",
    "    tweets.append(eval(tweet))\n",
    "    \n",
    "# find all unique words\n",
    "uniqueWords = {}\n",
    "words = []\n",
    "wordIndex = {}\n",
    "for tweet in tweets:\n",
    "    for word in tweet:\n",
    "        if word in uniqueWords.keys():\n",
    "            uniqueWords[word] += 1\n",
    "        else:\n",
    "            words.append(word)\n",
    "            wordIndex[word] = len(words)-1\n",
    "            uniqueWords[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3035, 4820)\n"
     ]
    }
   ],
   "source": [
    "# build a matrix A\n",
    "# each row i refers to a tweet\n",
    "# entry A_(i,j) has the number of times word j shows up in tweet i\n",
    "\n",
    "matrix = np.zeros([len(tweets), len(uniqueWords.keys())])\n",
    "print(matrix.shape)\n",
    "\n",
    "for i, tweet in enumerate(tweets):\n",
    "    for w, word in enumerate(tweet):\n",
    "        wordIdx = wordIndex[word]\n",
    "        matrix[i, wordIdx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svd(n):\n",
    "    cached = get_svd.memory.get(n, None)\n",
    "    if cached is not None:\n",
    "        return cached\n",
    "    else:\n",
    "        svd = TruncatedSVD(n_components = n)\n",
    "        svd.fit(matrix)\n",
    "        get_svd.memory[n] = svd\n",
    "        return svd\n",
    "get_svd.memory = dict()\n",
    "\n",
    "def get_reduced_tweets(n):\n",
    "    cached = get_reduced_tweets.memory.get(n, None)\n",
    "    if cached is not None:\n",
    "        return cached\n",
    "    else:\n",
    "        svd = get_svd(n)\n",
    "        reduced = svd.transform(matrix)\n",
    "        get_reduced_tweets.memory[n] = reduced\n",
    "        return reduced\n",
    "get_reduced_tweets.memory = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(n, q, k):\n",
    "    \"\"\" Looks for the K closest tweets in the reduced data in R^n (the argument of the function)\n",
    "    The query q should be a string, for example composed of terms or a tweet\n",
    "    \n",
    "    Returns the ***indices*** of the K closest matches \"\"\"\n",
    "    words = q.split()\n",
    "    stemmed = list(map(lambda w: stemmer.stem(w), words))\n",
    "    print(stemmed)\n",
    "    # build the vector with the right representation\n",
    "    vec = np.zeros([1, len(uniqueWords.keys())])\n",
    "    for i, word in enumerate(stemmed):\n",
    "        idx = wordIndex.get(word, None)\n",
    "        if idx is None:\n",
    "            # if this word has never been seen, let the user know\n",
    "            print(f\"Ignoring word '{words[i]}'\")\n",
    "        else:\n",
    "            vec[0, idx] += 1\n",
    "    print()\n",
    "    \n",
    "    # transform the vector\n",
    "    svd = get_svd(n)\n",
    "    transformed = svd.transform(vec)\n",
    "    \n",
    "    # find the closest vectors\n",
    "    tweets = get_reduced_tweets(n)\n",
    "    sims = cosine_similarity(tweets, transformed)\n",
    "    \n",
    "    # return the top k similarities\n",
    "    tops = []\n",
    "    for i in range(k):\n",
    "        tops.append(np.argmax(sims))\n",
    "        sims[tops[-1]] = -100\n",
    "    return tops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'automobil', 'vehicl']\n",
      "\n",
      "“Ford has abruptly killed a plan to sell a Chinese-made small vehicle in the U.S. because of the prospect of higher U.S. Tariffs.” CNBC.  This is just the beginning. This car can now be BUILT IN THE U.S.A. and Ford will pay no tariffs!\n",
      "\n",
      "Canada charges the U.S. a 270%  tariff on Dairy Products! They didn’t tell you that, did they? Not fair to our farmers!\n",
      "\n",
      "If the U.S. sells a car into China, there is a tax of 25%. If China sells a car into the U.S., there is a tax of 2%. Does anybody think that is FAIR? The days of the U.S. being ripped-off by other nations is OVER!\n",
      "\n",
      "China has agreed to reduce and remove tariffs on cars coming into China from the U.S. Currently the tariff is 40%.\n",
      "\n",
      "“U.S. Stocks Widen Global Lead” https://t.co/Snhv08ulcO\n",
      "\n",
      "The U.S. is respected again! https://t.co/NtQ4vsoqnk\n",
      "\n",
      "Secretary of Commerce Wilbur Ross will be speaking with representatives of the European Union about eliminating the large Tariffs and Barriers they use against the U.S.A. Not fair to our farmers and manufacturers.\n",
      "\n",
      "Iranian Harassment of U.S. Warships:\r\n",
      "\r\n",
      "2015: 22\r\n",
      "2016: 36\r\n",
      "2017: 14\r\n",
      "2018: 0\r\n",
      "\r\n",
      "Source: @USNavy\n",
      "\n",
      ".....China had agreed to start “immediately” buying U.S. products.” @business\n",
      "\n",
      "Based on Justin’s false statements at his news conference, and the fact that Canada is charging massive Tariffs to our U.S. farmers, workers and companies, I have instructed our U.S. Reps not to endorse the Communique as we look at Tariffs on automobiles flooding the U.S. Market!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# does trump ever talk about cars..?\n",
    "q = \"car automobile vehicle\"\n",
    "dim = 20\n",
    "topK = 10\n",
    "idxs = query(dim, q, topK)\n",
    "\n",
    "# print the closest matches\n",
    "for idx in idxs:\n",
    "    print(text_tweets[\"text\"][idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'so', 'great', 'and', 'incred']\n",
      "Ignoring word 'i'\n",
      "Ignoring word 'am'\n",
      "Ignoring word 'so'\n",
      "Ignoring word 'and'\n",
      "\n",
      "Gina is Great! https://t.co/TyLQ2W42y5\n",
      "\n",
      ".@seanhannity on @foxandfriends now! Great! 8:18 A.M.\n",
      "\n",
      "Promises Kept for our GREAT Veterans! https://t.co/C0h8cW4FuH\n",
      "\n",
      "Great to be in Singapore, excitement in the air!\n",
      "\n",
      "Happy 243rd Birthday to our GREAT @USNavy! #243NavyBday https://t.co/m1YtoKSHFw\n",
      "\n",
      "Great couple, great book! https://t.co/cLDI79rin8\n",
      "\n",
      "Don’t miss our GREAT @FLOTUS, Melania, on @ABC @ABC2020 tonight at 10pmE. Enjoy!\n",
      "\n",
      "The Queen of Soul, Aretha Franklin, is dead. She was a great woman, with a wonderful gift from God, her voice. She will be missed!\n",
      "\n",
      "I will be interviewed tonight by Trish Regan on @FoxBusiness at 8:00 P.M., right after the great Lou Dobbs!\n",
      "\n",
      "Budd and Mark, two great patriots for Congress! https://t.co/xx0cqUf7wj\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find tweets that could look similar to this one\n",
    "q = \"i am so great and incredible\"\n",
    "dim = 40\n",
    "topK = 10\n",
    "idxs = query(dim, q, topK)\n",
    "\n",
    "# print the closest matches\n",
    "for idx in idxs:\n",
    "    print(text_tweets[\"text\"][idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
